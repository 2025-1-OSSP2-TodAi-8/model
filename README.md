## í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°ì • ë¶„ì„ ëª¨ë¸

[![ğŸ¤— Hugging Face](https://img.shields.io/badge/HuggingFace-Text%20Emotion%20Model-yellow)](https://huggingface.co/HyukII/text-emotion-model)

- Model card: **HyukII/text-emotion-model**
- Load in code:
```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification
tok = AutoTokenizer.from_pretrained("HyukII/text-emotion-model")
model = AutoModelForSequenceClassification.from_pretrained("HyukII/text-emotion-model").eval()
```
---
## ğŸ¤ ì˜¤ë””ì˜¤ ê¸°ë°˜ ê°ì • ë¶„ì„ ëª¨ë¸
[![ğŸ¤— Model on HF](https://img.shields.io/badge/HuggingFace-Audio%20Emotion%20Model-yellow)](https://huggingface.co/HyukII/audio-emotion-model)

### ğŸ“Œ 1. ê°œìš”
- ì‚¬ìš©ìì˜ ë…¹ìŒ ìŒì„±ì„ ì…ë ¥ë°›ì•„ ìŒí–¥ì  íŠ¹ì§•ì„ ì¶”ì¶œí•˜ê³  ê°ì •ì„ ë¶„ë¥˜í•˜ëŠ” ëª¨ë¸
- í…ìŠ¤íŠ¸ ë¶„ì„ ëª¨ë¸ê³¼ ë‹¬ë¦¬, ëª©ì†Œë¦¬ì˜ ì–µì–‘Â·ì†ë„Â·ì—ë„ˆì§€Â·ìŠ¤í™íŠ¸ëŸ¼ ë³€í™” ë“±ì„ í™œìš©í•´ ê°ì •ì„ ê°ì§€
- ì¼ê¸° í…ìŠ¤íŠ¸ê°€ ê¸ì •ì ìœ¼ë¡œ ì‘ì„±ë˜ë”ë¼ë„, ëª©ì†Œë¦¬ í†¤ì´ ìš°ìš¸í•˜ë‹¤ë©´ ì‹¤ì œ ê°ì •ì„ ë³´ì™„ì ìœ¼ë¡œ íŒŒì•…í•  ìˆ˜ ìˆìŒ

### ğŸ› ï¸ 2. íŠ¹ì§• ì¶”ì¶œ (Feature Extraction)
ë³¸ í”„ë¡œì íŠ¸ì—ì„œëŠ” ìŒì„±ì—ì„œ MFCC(Mel-Frequency Cepstral Coefficients)ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  ìˆìŒ
- MFCC (Mel-Frequency Cepstral Coefficients): ìŒì„±ì˜ ì£¼íŒŒìˆ˜ ìŠ¤í™íŠ¸ëŸ¼ì„ ìš”ì•½í•œ 13ì°¨ì› ê³„ìˆ˜
- ê³ ì •ëœ ì‹œí€€ìŠ¤ ê¸¸ì´: 100 í”„ë ˆì„ìœ¼ë¡œ ë§ì¶”ì–´ CNN-LSTM ëª¨ë¸ì— ì…ë ¥ ê°€ëŠ¥
- íŒ¨ë”© / ìë¥´ê¸° ì²˜ë¦¬: ë°œí™” ê¸¸ì´ê°€ ì§§ìœ¼ë©´ 0ìœ¼ë¡œ íŒ¨ë”©, ê¸¸ë©´ ì˜ë¼ëƒ„
- ì‚¬ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬: librosa, numpy

### ğŸ” 3. ëª¨ë¸ êµ¬ì¡°
- CNN + BiLSTM ê¸°ë°˜ ì‹œí€€ìŠ¤ ëª¨ë¸
- Conv1D â†’ ìŒí–¥ ìŠ¤í™íŠ¸ëŸ¼ íŠ¹ì§• ì¶”ì¶œ
- BiLSTM â†’ ì‹œê°„ì  ë³€í™” íŒ¨í„´ í•™ìŠµ
- Dense + Softmax â†’ ê°ì • í´ë˜ìŠ¤ í™•ë¥  ì¶œë ¥


### âš™ï¸ 4.í•™ìŠµ ë°©ë²•
4.1. ë°ì´í„°ì…‹ êµ¬ì„±
- í›ˆë ¨ ë°ì´í„° : AiHubì˜ 'ê°ì • ìŒì„± ë°ì´í„°ì…‹' (https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&dataSetSn=637)
- ì‚¬ìš©ì ìŒì„± â†’ 9~13ì°¨ì› íŠ¹ì§• ë²¡í„°(MFCC ë“±) ì‹œí€€ìŠ¤ë¡œ ë³€í™˜
- ë ˆì´ë¸”: ê°ì • í´ë˜ìŠ¤ (ì˜ˆ: JOY, SAD, ANGRY ë“±)
- ë¶ˆê· í˜• ë³´ì™„: ë°ì´í„° ì¦ê°•(ì†ë„ ë³€í™˜, í”¼ì¹˜ ì‰¬í”„íŠ¸)

4.2. í›ˆë ¨ ì „ëµ
- ì…ë ¥: (ì‹œí€€ìŠ¤ ê¸¸ì´, feature_dim) í˜•íƒœì˜ ìŒì„± íŠ¹ì§• ì‹œí€€ìŠ¤
- ì¶œë ¥: ê°ì • í™•ë¥  ë¶„í¬ (Softmax)
- ì†ì‹¤ í•¨ìˆ˜: CrossEntropyLoss
- ì˜µí‹°ë§ˆì´ì €: AdamW, learning rate scheduling ì ìš©

4.3. ì¤‘ë¦½ ë²¡í„° ê¸°ë°˜ ë¶„ì„ (Delta Approach)
- ë‚¨ì, ì—¬ììš©  Neutral Baseline Vectorë¥¼ ë¨¼ì € ì €ì¥
- ìƒˆë¡œìš´ ë°œí™” ì…ë ¥ ì‹œ â†’ Î” = (í˜„ì¬ ë²¡í„° â€“ baseline) ê³„ì‚°
- Î” ë²¡í„°ë¥¼ ëª¨ë¸ì— ì…ë ¥í•˜ì—¬ ê°œì¸í™”ëœ ê°ì • ì˜ˆì¸¡ ê°€ëŠ¥

  
#### Model card: **HyukII/audio-emotion-model**

#### Load in code:
```python
import json, torch, numpy as np
from huggingface_hub import hf_hub_download
from importlib.machinery import SourceFileLoader

repo = "HyukII/audio-emotion-model"
w = hf_hub_download(repo, "pytorch_model.pth")
m = hf_hub_download(repo, "model.py")
lab = hf_hub_download(repo, "labels.json")

labels = json.load(open(lab, encoding="utf-8"))
Model = SourceFileLoader("amodel", m).load_module().PyTorchAudioModel

model = Model(num_labels=len(labels)).eval()
state = torch.load(w, map_location="cpu")
model.load_state_dict(state)
# x: tensor (1,13,100) â†’ probs = softmax(model(x), dim=1)



